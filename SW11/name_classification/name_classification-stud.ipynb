{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "The names can be found in text files in a src directory, one file per language.\n",
    "\n",
    "In the following you can find some utilities to load the data into pandas data frames. \n",
    "\n",
    "We will restrict to some common European languages. \n",
    "\n",
    "With the given selection, we will identify all the occurring characters and initialize an alphabet.<br>\n",
    "For this alphabet, we will use a one-hot-encoding to map them into a vector space representation. \n",
    "\n",
    "Foresee a suitable character for the end of the word, e.g. 'END'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcdir = 'data/names'\n",
    "languages = [\"English\",\"French\",\"Italian\",\"German\",\"Spanish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the data directory\n",
    "def findFiles(path): \n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_classification/data/names/Czech.txt\n",
      "name_classification/data/names/German.txt\n",
      "name_classification/data/names/Arabic.txt\n",
      "name_classification/data/names/Japanese.txt\n",
      "name_classification/data/names/Chinese.txt\n",
      "name_classification/data/names/Vietnamese.txt\n",
      "name_classification/data/names/Russian.txt\n",
      "name_classification/data/names/French.txt\n",
      "name_classification/data/names/Irish.txt\n",
      "name_classification/data/names/English.txt\n",
      "name_classification/data/names/Spanish.txt\n",
      "name_classification/data/names/Greek.txt\n",
      "name_classification/data/names/Italian.txt\n",
      "name_classification/data/names/Portuguese.txt\n",
      "name_classification/data/names/Scottish.txt\n",
      "name_classification/data/names/Dutch.txt\n",
      "name_classification/data/names/Korean.txt\n",
      "name_classification/data/names/Polish.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(findFiles(os.path.join(srcdir,'*.txt'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return lines\n",
    "\n",
    "def load_data(srcdir, categories=None):\n",
    "    names_list = []\n",
    "    for filename in findFiles(os.path.join(srcdir,'*.txt')):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        if not categories or category in categories: \n",
    "            names = readLines(filename)\n",
    "            names_list.extend([(name,category) for name in names])\n",
    "    df = pd.DataFrame(names_list)\n",
    "    df.columns = [\"name\",\"lang\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbing</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abel</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abeln</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abt</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Achilles</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name    lang\n",
       "0    Abbing  German\n",
       "1      Abel  German\n",
       "2     Abeln  German\n",
       "3       Abt  German\n",
       "4  Achilles  German"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = load_data(srcdir,categories=languages)\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum name length:  18\n"
     ]
    }
   ],
   "source": [
    "maxlen = np.max([len(name) for name in names.name])\n",
    "print(\"Maximum name length: \", maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of alphabet:  74\n",
      "[' ', \"'\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Á', 'É', 'ß', 'à', 'á', 'ä', 'ç', 'è', 'é', 'ê', 'ì', 'í', 'ñ', 'ò', 'ó', 'ö', 'ù', 'ú', 'ü', 'END']\n"
     ]
    }
   ],
   "source": [
    "alphabet = sorted(list(set(''.join([name for name in names.name]))))\n",
    "alphabet.append('END')\n",
    "len_alphabet = len(alphabet)\n",
    "char_index = dict((c, i) for i, c in enumerate(alphabet))\n",
    "print(\"Size of alphabet: \",len_alphabet)\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang\n",
       "English    0.646230\n",
       "French     0.048802\n",
       "German     0.127555\n",
       "Italian    0.124912\n",
       "Spanish    0.052502\n",
       "Name: name, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.groupby('lang')['name'].count()/len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Representations\n",
    "\n",
    "Now construct the vector representation by using one-hot-vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_to_index = {country:index for index,country in enumerate(names.lang.unique())}\n",
    "index_to_language = {index:country for index,country in enumerate(names.lang.unique())}\n",
    "\n",
    "def onehot(i, length):\n",
    "    v = np.zeros(length);\n",
    "    v[i] = 1\n",
    "    return v\n",
    "\n",
    "def name_representation(name, maxlen):\n",
    "    ### START YOUR CODE\n",
    "    name_trunc = str(name)[0:maxlen]\n",
    "    size = len(char_index)\n",
    "    vector = [onehot(char_index[j], size) for j in str(name)]\n",
    "    # fill the rest with \n",
    "    for k in range(0,maxlen - len(str(name))):\n",
    "        vector.append(onehot(char_index['END'], size))\n",
    "    return vector\n",
    "    ### START YOUR CODE\n",
    "\n",
    "def lang_representation(language, language_to_index):\n",
    "    y = np.zeros(len(language_to_index))\n",
    "    y[language_to_index[language]]=1\n",
    "    return y\n",
    "\n",
    "def lang_from_output(score):\n",
    "    return index_to_language[np.argmax(score)]\n",
    "\n",
    "def predict(name, model):\n",
    "    score = model.predict(np.array([name_representation(name, maxlen)]))[0]\n",
    "    return lang_from_output(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/test\n",
    "\n",
    "Split the data into train/test\n",
    "\n",
    "Shuffle the data\n",
    "\n",
    "Transform the names data into a suitable vector respresentation:\n",
    "* names into numpy arrays of shape (*,maxlen,len_alphabet)\n",
    "* language into numpy array of shape (*,len(languages))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "### START YOUR CODE\n",
    "# Shuffle and split names data\n",
    "\n",
    "train = ...\n",
    "\n",
    "test = ...\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "\n",
    "# Map train and test data into vector space (one-hot-vectors)\n",
    "\n",
    "X_train = ...\n",
    "Y_train = ...\n",
    "\n",
    "X_test = ...\n",
    "Y_test = ...\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_plots(model, X_test, Y_test, log, epochs):    \n",
    "    acc = log.history['accuracy']\n",
    "    val_acc = log.history['val_accuracy']\n",
    "    print('Train accuracy (end):', acc[-1])\n",
    "    print('Train accuracy (max):', np.max(acc))\n",
    "    print('Test accuracy (end) :', val_acc[-1])\n",
    "    print('Test accuracy (max) :', np.max(val_acc))\n",
    "\n",
    "    plt.plot(log.history['accuracy'])\n",
    "    plt.plot(log.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc='upper left')\n",
    "    plt.axis([0,epochs,0.0,1.0])\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(log.history['loss'])\n",
    "    plt.plot(log.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc = 'upper left')\n",
    "    plt.axis([0,epochs,0.0,2.0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "def confusion_matrix(model, X_test, Y_test):\n",
    "    scores = model.predict(X_test)\n",
    "    predictions = np.argmax(scores, axis=1)\n",
    "    labels = np.argmax(Y_test, axis=1)\n",
    "    nsamples = Y_test.shape[0]\n",
    "    cm = sklearn.metrics.confusion_matrix(labels, predictions)\n",
    "    df = pd.DataFrame({languages[i] : cm[:,i] for i in range(len(languages))}, languages)\n",
    "    return df, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train Model: Single Layer with SimpleRNN\n",
    "\n",
    "Create an RNN consisting of a single layer with a SimpleRNN (keras) and a softmax.\n",
    "\n",
    "Then train the model. Play with different number of hidden units in the layer to obtain a good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "\n",
    "# SImpleRNN, single layer with tf.keras....\n",
    "\n",
    "model = ...\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 4545 samples, validate on 1131 samples\n",
      "Epoch 1/10\n",
      "4545/4545 [==============================] - 3s 758us/sample - loss: 1.1283 - accuracy: 0.6345 - val_loss: 1.0387 - val_accuracy: 0.6525\n",
      "Epoch 2/10\n",
      "4545/4545 [==============================] - 2s 340us/sample - loss: 0.9673 - accuracy: 0.6693 - val_loss: 0.9022 - val_accuracy: 0.6941\n",
      "Epoch 3/10\n",
      "4545/4545 [==============================] - 1s 322us/sample - loss: 0.8295 - accuracy: 0.7043 - val_loss: 0.8138 - val_accuracy: 0.7135\n",
      "Epoch 4/10\n",
      "4545/4545 [==============================] - 2s 382us/sample - loss: 0.7588 - accuracy: 0.7274 - val_loss: 0.7944 - val_accuracy: 0.7197\n",
      "Epoch 5/10\n",
      "4545/4545 [==============================] - 2s 358us/sample - loss: 0.7347 - accuracy: 0.7360 - val_loss: 0.7714 - val_accuracy: 0.7383\n",
      "Epoch 6/10\n",
      "4545/4545 [==============================] - 2s 401us/sample - loss: 0.6700 - accuracy: 0.7613 - val_loss: 0.7087 - val_accuracy: 0.7480\n",
      "Epoch 7/10\n",
      "4545/4545 [==============================] - 2s 398us/sample - loss: 0.7053 - accuracy: 0.7468 - val_loss: 0.7178 - val_accuracy: 0.7507\n",
      "Epoch 8/10\n",
      "4545/4545 [==============================] - 2s 372us/sample - loss: 0.6371 - accuracy: 0.7736 - val_loss: 0.7169 - val_accuracy: 0.7409\n",
      "Epoch 9/10\n",
      "4545/4545 [==============================] - 2s 403us/sample - loss: 0.6331 - accuracy: 0.7672 - val_loss: 0.7302 - val_accuracy: 0.7401\n",
      "Epoch 10/10\n",
      "4545/4545 [==============================] - 2s 403us/sample - loss: 0.5936 - accuracy: 0.7842 - val_loss: 0.6877 - val_accuracy: 0.7524\n"
     ]
    }
   ],
   "source": [
    "### START YOUR CODE\n",
    "batch_size=\n",
    "nepochs = \n",
    "\n",
    "log = model.fit(X_train, Y_train, batch_size=batch_size, \\\n",
    "                nb_epoch=nepochs, validation_data=(X_test, Y_test))\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_plots(model, X_test, Y_test, log, nepochs)\n",
    "df, cm = confusion_matrix(model, X_test, Y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Class Imbalance, Resampling\n",
    "\n",
    "We can observe a quite significant class imbalance in the data.<br>\n",
    "\n",
    "One way to compensate for that would be to use resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_imbalance(names, languages):\n",
    "\n",
    "    ### START YOUR CODE\n",
    "\n",
    "    # treat class imbalance\n",
    "    names_upsampled = \n",
    "\n",
    "    ### END YOUR CODE    \n",
    "    return names_upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang\n",
       "English    0.2\n",
       "French     0.2\n",
       "German     0.2\n",
       "Italian    0.2\n",
       "Spanish    0.2\n",
       "Name: name, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_upsampled = handle_imbalance(names, languages)\n",
    "names_upsampled.groupby('lang')['name'].count()/len(names_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model\n",
    "\n",
    "Again prepare train and test data (X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "Train the same model as above with the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "\n",
    "X_train = ...\n",
    "X_test = ...\n",
    "\n",
    "Y_train = ...\n",
    "Y_test = ...\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "\n",
    "# train model\n",
    "\n",
    "...\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In which situations is class imbalance treatment important and why?  \n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Model with several SimpleRNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "\n",
    "model = ...\n",
    "\n",
    "### END YOUR CODE\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "\n",
    "# train...\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
