{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Computational Graph sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "logdir = 'logs/'\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "tf.summary.trace_on(graph=True, profiler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def build():\n",
    "    x1 = tf.constant(1, dtype=tf.float32, name=\"x1\")\n",
    "    x2 = tf.constant(2, dtype=tf.float32, name=\"x2\")\n",
    "    w1 = tf.constant(3, dtype=tf.float32, name=\"w1\")\n",
    "    w2 = tf.constant(4, dtype=tf.float32, name=\"w2\")\n",
    "    b = tf.constant(5, dtype=tf.float32, name=\"b\")\n",
    "\n",
    "    z = -(w1*x1+w2*x2+b)\n",
    "    a = 1 / (1 + tf.math.exp(z))\n",
    "    return tf.gradients(ys=a, xs=[x1, w1, x2, w2])\n",
    "\n",
    "\n",
    "build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name='NN',\n",
    "        step=0,\n",
    "        profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison we also include the graph that \n",
    "![](tf-graph.png)\n",
    "As we can see, tensorflow also included the gradients calculation into the graph. If we expand the gradients node, we can see that it is equivalent to the manual calculation we made above.\n",
    "![](tf-graph-grad.png)\n",
    "\n",
    "\n",
    "If we now also expand the nodes of the granular gradient calculation, we can observe how tensorflow calculates this gradient with granular operations. Notice that the gradient is initialized right before the truediv grad and then passed on and multiplied according to the chain rule.\n",
    "\n",
    "\n",
    "### Grad Mul\n",
    "![](grad-mul.png)\n",
    "\n",
    "### Grad Neg\n",
    "![](grad-neg.png)\n",
    "\n",
    "### Grad Exp\n",
    "![](grad-exp.png)\n",
    "\n",
    "### Grad Truediv\n",
    "Notice here that\n",
    "\n",
    "$$\n",
    "\\frac{\\frac{-1}{x}}{x} = \\frac{-1}{x} : x = \\frac{-1}{x} \\cdot \\frac{1}{x} = \\frac{-1}{x^2} \n",
    "$$\n",
    "\n",
    "![](grad-truediv.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
