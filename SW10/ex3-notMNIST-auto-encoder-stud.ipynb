{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(28 * 28 * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, 28,28)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        return labels\n",
    "\n",
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: 'A',\n",
    " 1: 'B',\n",
    " 2: 'C',\n",
    " 3: 'D',\n",
    " 4: 'E',\n",
    " 5: 'F',\n",
    " 6: 'G',\n",
    " 7: 'H',\n",
    " 8: 'I',\n",
    " 9: 'J',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = extract_data('train-images-idx3-ubyte.gz', 60000)\n",
    "test_data = extract_data('t10k-images-idx3-ubyte.gz', 10000)\n",
    "\n",
    "train_labels = extract_labels('train-labels-idx1-ubyte.gz',60000)\n",
    "test_labels = extract_labels('t10k-labels-idx1-ubyte.gz',10000)\n",
    "\n",
    "X_train = train_data.reshape(-1, 28,28, 1)  # add grey channel\n",
    "X_test = test_data.reshape(-1, 28,28, 1)\n",
    "\n",
    "n_classes = 10\n",
    "Y_train = utils.to_categorical(train_labels, n_classes) # 1-hot\n",
    "Y_test = utils.to_categorical(test_labels, n_classes)\n",
    "print(Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=X_train.shape))\n",
    "# Shape of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=X_test.shape))\n",
    "# Type of data - should be float32\n",
    "print('data type: ', X_train.dtype, X_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(X_train[0], (28,28))\n",
    "curr_lbl = train_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(X_test[0], (28,28))\n",
    "curr_lbl = test_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the data in range 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a shallow MLP encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STARTING FROM HERE, COMPLETE THE CODE WHERE YOU SEE ...\n",
    "# size of our encoded representation\n",
    "encoding_dim = ...  #Â this is the number of neurons you chose to encode\n",
    "\n",
    "# define input layer, encoded layer and decoded layer\n",
    "input_img = ...\n",
    "encoded = ...\n",
    "decoded = ...\n",
    "\n",
    "# define autoencoder model \n",
    "autoencoder = Model(...)\n",
    "encoder = Model(...)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(...)\n",
    "\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = ...\n",
    "\n",
    "# create the decoder model\n",
    "decoder = Model(...)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the network - use adam optimizer, beware to use the good loss function\n",
    "autoencoder.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualisation\n",
    "def plot_result(x_test,decoded_imgs):\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(60000,784)\n",
    "X_test_flat = X_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the network\n",
    "log = autoencoder.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log.history['loss'], label='Training')\n",
    "plt.plot(log.history['val_loss'], label='Testing')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(X_test_flat)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "plot_result(X_test_flat,decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the encoded features to train another classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feat = encoder.predict(X_train_flat)\n",
    "X_test_feat = encoder.predict(X_test_flat)\n",
    "\n",
    "# Normalization (standardization) of training and test sets\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train_feat)\n",
    "X_train_feat = scaler.transform(X_train_feat)  \n",
    "X_test_feat = scaler.transform(X_test_feat)\n",
    "\n",
    "print(X_train_feat.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test_feat.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the features to train a SVM\n",
    "clf = SVC(kernel='linear', cache_size=7000)\n",
    "clf.fit(X_train_feat, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_feat)\n",
    "\n",
    "# Print classification results with confusion matrix\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\" %\n",
    "      (clf, metrics.classification_report(test_labels, y_pred)))\n",
    "# print(\"\\nConfusion matrix:\\n%s\" % metrics.confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a conv autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(...)\n",
    "# encoder\n",
    "conv1 = ... #28 x 28 x 32\n",
    "pool1 = ... #14 x 14 x 32\n",
    "conv2 = ... #14 x 14 x 64\n",
    "pool2 = ... #7 x 7 x 64\n",
    "conv3 = ... #7 x 7 x 128 (small and thick)\n",
    "# decoder\n",
    "conv4 = ... #7 x 7 x 128\n",
    "up1 = ... # 14 x 14 x 128 (UpSampling2D())\n",
    "conv5 = ... # 14 x 14 x 64\n",
    "up2 = ... # 28 x 28 x 64\n",
    "decoded = ... # 28 x 28 x 1\n",
    "# autoencoder\n",
    "autoencoder = Model(inputs=..., outputs=...)\n",
    "autoencoder.compile(...)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = autoencoder.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test, verbose=0)\n",
    "print(decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(X_test_flat,decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising autoencoder\n",
    "First add some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = ... #chose a noise factor between 0.0 and 1.0\n",
    "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
    "X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "X_test_noisy = np.clip(X_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(X_train_noisy[1], (28,28))\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(X_test_noisy[1], (28,28))\n",
    "plt.imshow(curr_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDEFINE HERE A CONV AUTOENCODER FOR THE DENOISING WITH A SIMILAR ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the noisy images and use as target the original clean images\n",
    "log = autoencoder.fit(X_train_noisy, X_train, batch_size=128, epochs=1,\n",
    "                        verbose=1, validation_data=(X_test_noisy, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test_noisy, verbose=0)\n",
    "print(decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(X_test_noisy,decoded_imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
