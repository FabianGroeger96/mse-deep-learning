{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Digits Classification - Binary Case\n",
    "\n",
    "In this exercise, you will implement a binary classification of MNIST digits. You will restrict the classification problem to two digits selected from the MNIST dataset.\n",
    "\n",
    "You will conduct the follwing steps:\n",
    "1. Prepare the data: \n",
    "    * Load the MNIST dataset\n",
    "    * Select the digits\n",
    "    * Split the dataset into train and test (we keep it simpler at the moment and ignore the validation set)\n",
    "    * Standardize the data\n",
    "\n",
    "\n",
    "2. Implement the training algorithm consisting of\n",
    "    * sigmoid model function and predict function\n",
    "    * cost function\n",
    "    * parameter update rules \n",
    "    * optimize loop\n",
    "\n",
    "\n",
    "3. Train the model for specific settings and get a feeling for how the training evolves\n",
    "    * learning rate\n",
    "    * number of epochs\n",
    "    * CE / MSE loss\n",
    "    * differently, randomly initialized weights\n",
    "    \n",
    "Some of the functions are already implemented. You just need to use these functions - but we highly recommend to inspect them and try to understand each and every line of the code. - In case you have suggestions for improvements we are very happy to receive your feedback.\n",
    "\n",
    "Other functions need to be implemented by you. Carefully read the markdown sections and also the doc-strings and run the test cells often given in the cell right after. \n",
    "\n",
    "The following notation is used: <br>\n",
    "<code>m</code>: Number of samples <br>\n",
    "<code>n</code>: Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation\n",
    "\n",
    "Some preparatory steps to be applied before training:\n",
    "* Loading the data\n",
    "* Some plots\n",
    "* Filtering the dataset for two digits\n",
    "* Splitting the dataset into train and test\n",
    "* Normalizing the data\n",
    "\n",
    "#### Data Folder\n",
    "\n",
    "The data can be loaded by using suitable functionality in sklearn which will use a dedicated folder on your local disk for caching. Specify the folder to be used with a variable of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# adjust:\n",
    "path_data = './data/'\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img, label, shape):\n",
    "    \"\"\"\n",
    "    Plot the x array by reshaping it into a square array of given shape\n",
    "    and print the label.\n",
    "    \n",
    "    Parameters:\n",
    "    img -- array with the intensities to be plotted of shape (shape[0]*shape[1])\n",
    "    label -- label \n",
    "    shape -- 2d tuple with the dimensions of the image to be plotted.\n",
    "    \"\"\"\n",
    "    plt.imshow(np.reshape(img, shape), cmap=plt.cm.gray)\n",
    "    plt.title(\"Label %i\"%label)\n",
    "\n",
    "def plot_digits(x,y,selection,shape,selected_digits, cols=5):\n",
    "    \"\"\"\n",
    "    Plots the digits in a mosaic with up to 8 columns\n",
    "\n",
    "    Arguments:\n",
    "    x -- array of images of size (n,m)\n",
    "    y -- array of labels of size (1,m)\n",
    "    selection -- list of selection of samples to be plotted\n",
    "    shape -- shape of the images (a 2d tuple)\n",
    "    selected_digits -- tuple with the two selected digits (the first associated with label 1, the second with label 0)\n",
    "    \"\"\"\n",
    "    if len(selection)==0:\n",
    "        print(\"No images in the selection!\")\n",
    "        return\n",
    "    cols = min(cols, len(selection))\n",
    "    rows = int(len(selection)/cols)+1\n",
    "    plt.figure(figsize=(20,4*rows))\n",
    "    digit1 = selected_digits[0]\n",
    "    digit2 = selected_digits[1]    \n",
    "    for index, (image, label) in enumerate(zip(x.T[selection,:], y.T[selection,:])):\n",
    "        digit = digit1 if label==1 else digit2\n",
    "        plt.subplot(rows, cols, index+1)\n",
    "        plt.imshow(np.reshape(image, shape), cmap=plt.cm.gray)\n",
    "        plt.title('Sample %i\\n Label %i\\n' % (selection[index],digit), fontsize = 12)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data \n",
    "\n",
    "Follow the instructions in the doc string of the <span style=\"color:blue\">load_mnist</span>-method defined below so that you can load the \"MNIST original\" dataset.\n",
    "\n",
    "Load the data MNIST dataset and plot the 17th image by using the <span style=\"color:blue\">plot_image</span>-method defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def load_mnist(datadir):\n",
    "    \"\"\"\n",
    "    Loads the mnist dataset, prints the shape of the dataset and \n",
    "    returns the array with the images, the array with associated labels \n",
    "    and the shape of the images. Possibly, the data needs to be fetched \n",
    "    manually beforehand and put into the folder DATA_HOME/mldata \n",
    "    (see https://stackoverflow.com/questions/53096977/mnist-data-download-from-sklearn-datasets-gives-timeout-error)\n",
    "    \n",
    "    Returns:\n",
    "    x -- array with images of shape (784,m) where m is the number of images\n",
    "    y -- array with associated labels with shape (m,) where m is the number of images\n",
    "    shape -- (28,28)\n",
    "    \"\"\"\n",
    "    mnist = fetch_openml('mnist_784', data_home=datadir)\n",
    "    x, y = mnist['data'].T, np.array(mnist['target'], dtype='int').T\n",
    "    m = x.shape[1]\n",
    "    y = y.reshape(1,m)\n",
    "    print(\"Loaded MNIST original:\")\n",
    "    print(\"Image Data Shape\" , x.shape)\n",
    "    print(\"Label Data Shape\", y.shape)\n",
    "    return x,y,(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, shape = load_mnist(path_data)\n",
    "\n",
    "### START YOUR CODE ###\n",
    "plot_img(x[:, 16], label=y[:, 16], shape=shape)\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the data for two selected digits and split it into train/test\n",
    "\n",
    "Load the MNIST dataset (by using <span style=\"color:blue\">load_mnist</span> from above), filter it to only use the digits '1' and '7' (by using the method <span style=\"color:blue\">filter_digits</span> and split up the result further into a training and a test set (by using the <span style=\"color:blue\">prepare_train_test</span>). Use a 80-20 split of the data into train and test.\n",
    "\n",
    "Furthermore, bring the input data (x) into the shape (n,m) where n is the number of input features and m the number of samples.  \n",
    "As a result, you can run the test which should not produce any exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_digits(x, y, selected_digits):\n",
    "    \"\"\"\n",
    "    Filter the dataset for given two digits (label values between 0 and 9).\n",
    "    The samples with the first digit will be associated with the label 1, the second with 0.  \n",
    "    \n",
    "    Parameters:\n",
    "    x -- Array of images of shape (n,m) where m is the number of samples\n",
    "    y -- Array of labels of shape (1,m) where m is the number of samples\n",
    "    digits -- tuple with two values\n",
    "    \n",
    "    Returns:\n",
    "    x1 -- filtered list of images of shape (n,m1)\n",
    "    y1 -- filtered list of labels of shape (1,m1)\n",
    "    \"\"\"\n",
    "    # select two given digits - will the train a model that learns to differentiate between the two\n",
    "    \n",
    "    digit1, digit2 = selected_digits\n",
    "    \n",
    "    idx_digit1 = (y[0, :] == digit1)\n",
    "    idx_digit2 = (y[0, :] == digit2)\n",
    "    \n",
    "    idx_combined = (idx_digit1 | idx_digit2)\n",
    "    \n",
    "    x1 = x[:, idx_combined]\n",
    "    y1 = y[:, idx_combined]\n",
    "    \n",
    "    idx_digit1 = (y1[0, :] == digit1)\n",
    "    idx_digit2 = (y1[0, :] == digit2)\n",
    "    \n",
    "    y1[:, idx_digit1] = 1\n",
    "    y1[:, idx_digit2] = 0\n",
    "    \n",
    "\n",
    "    print(\"Selecting {} images with digit {} and {} images with digit {}\".format(\n",
    "        np.sum(idx_digit1),digit1,np.sum(idx_digit2),digit2))\n",
    "    return x1,y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_train_test(x, y, test_size=0.20):\n",
    "    \"\"\"\n",
    "    Split the dataset consisting of an array of images (shape (m,n)) and an array of labels (shape (n,))\n",
    "    into train and test set.\n",
    "    \n",
    "    Parameters:\n",
    "    x -- Array of images of shape (n,m) where m is the number of samples\n",
    "    y -- Array of labels of shape (m,) where m is the number of samples\n",
    "    test_size -- fraction of samples to reserve as test sample\n",
    "    \n",
    "    Returns:\n",
    "    x_train -- list of images of shape (n,m1) used for training\n",
    "    y_train -- list of labels of shape (1,m1) used for training\n",
    "    x_test -- list of images of shape (n,m2) used for testing\n",
    "    y_test -- list of labels of shape (1,m2) used for testing\n",
    "    \"\"\"\n",
    "    # split \n",
    "    # We use the functionality of sklearn which assumes that the samples are enumerated with the first index \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x.T, y.T, test_size=0.20, random_state=1)\n",
    "\n",
    "    # reshape - transpose back the output obtained from the train_test_split-function\n",
    "    x_train = x_train.T\n",
    "    x_test = x_test.T\n",
    "    m_train = x_train.shape[1]\n",
    "    m_test = x_test.shape[1]\n",
    "    y_train=y_train.reshape(1,m_train)\n",
    "    y_test=y_test.reshape(1,m_test)\n",
    "\n",
    "    print(\"Shape training set: \", x_train.shape, y_train.shape)\n",
    "    print(\"Shape test set:     \", x_test.shape, y_test.shape)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "# call the arrays x_train1, y_train, x_test1, y_test\n",
    "x1, y1 = filter_digits(x, y, selected_digits=(1,7))\n",
    "x_train1, x_test1, y_train, y_test = prepare_train_test(x1, y1, test_size=0.2)\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST ##\n",
    "np.testing.assert_array_equal(x_train1.shape, (784, 12136))\n",
    "np.testing.assert_array_equal(y_train.shape, (1, 12136))\n",
    "np.testing.assert_array_equal(x_test1.shape, (784, 3034))\n",
    "np.testing.assert_array_equal(y_test.shape, (1, 3034))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Normalisation\n",
    "\n",
    "Normalize the data - by using z-normalization computed over all pixels. \n",
    "Test that the result is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x_train,x_test):\n",
    "    \"\"\"\n",
    "    Normalizes the pixels values of the images - mean and stdev are computed from the training set.\n",
    "    \n",
    "    Parameters:\n",
    "    x_train -- Array of training samples of shape (n,m1) where n,m1 are the number of features and samples, respectively.  \n",
    "    x_test -- Array of test samples of shape (n,m2) where n,m2 are the number of features and samples, respectively. \n",
    "    \n",
    "    Returns:\n",
    "    The arrays with the normalized train and test samples.  \n",
    "    \"\"\"\n",
    "    ### START YOUR CODE ###\n",
    "    mean = np.mean(x_train)\n",
    "    std = np.std(x_train)\n",
    "    \n",
    "    x_train = (x_train - mean)/std\n",
    "    x_test = (x_test - mean)/std\n",
    "    ### END YOUR CODE ###\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST ##\n",
    "xunittest_train = np.array([0,3,2,5,10,9]).reshape(1,6).astype(np.float64)\n",
    "xunittest_test = np.array([11,20,1,-1]).reshape(1,4).astype(np.float64)\n",
    "x1,x2 = normalize(xunittest_train, xunittest_test)\n",
    "np.testing.assert_array_almost_equal(x1,np.array([-1.33342142, -0.50578054, -0.78166083,  0.04598005,  1.42538152,  1.14950122]).reshape(1,6),decimal=8)\n",
    "np.testing.assert_array_almost_equal(x2,np.array([1.70126181,  4.18418446, -1.05754113, -1.60930171]).reshape(1,4),decimal=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test = normalize(x_train1,x_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    ### START YOUR CODE ###\n",
    "    return 1/(1+np.exp(-z))\n",
    "    ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "zunittest = np.array([1,-2,2,0]).reshape(1,4)\n",
    "yunittest = sigmoid(zunittest)\n",
    "ytrue = np.array([0.73105858, 0.11920292, 0.88079708, 0.5]).reshape(1,4)\n",
    "np.testing.assert_array_almost_equal(yunittest,ytrue,decimal=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(w, b, X, round=False):\n",
    "    '''\n",
    "    Compute the prediction for each of the m samples by using the parameters (w, b).\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array with shape (1, n)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (n,m)\n",
    "    round -- return the score (number in [0,1]) if False, or round to 0 or 1 if True.\n",
    "    \n",
    "    Returns:\n",
    "    predictions -- a numpy array (vector) containing all predictions\n",
    "    '''    \n",
    "    ### START YOUR CODE ### \n",
    "    pred = sigmoid(w.dot(X) + b)\n",
    "    if round: return np.round(pred)\n",
    "    return pred\n",
    "    ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "X = np.array([1,-2,2,1]).reshape(4,1)\n",
    "w = np.array([1,1,0.75,0]).reshape(1,4)\n",
    "b = -0.25\n",
    "\n",
    "yunittest = predict(w,b,X)\n",
    "ytrue = np.array([sigmoid(0.25)]).reshape(1,1)\n",
    "np.testing.assert_array_almost_equal(yunittest,ytrue,decimal=8)\n",
    "\n",
    "yunittest = predict(w,b,X, round=True)\n",
    "ytrue = np.array([1]).reshape(1,1)\n",
    "np.testing.assert_array_almost_equal(yunittest,ytrue,decimal=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Function\n",
    "\n",
    "* Cross-Entropy Cost Function\n",
    "* Mean Square Error Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cost_CE(ypred, y, eps=1.0e-12):\n",
    "    \"\"\"\n",
    "    Computes the cross entropy cost function for given predicted values and labels.\n",
    "    It clips (using numpy clip) predicted values to be in the interval [eps,1-eps] so that numerical \n",
    "    issues with the calculation of logarithm are avoided.\n",
    "    \n",
    "    Parameters:\n",
    "    ypred -- Predicted values, a numpy array with shape (1,m).\n",
    "    y -- Ground truth values (labels 0 or 1), a numpy array with shape (1,m)\n",
    "    \n",
    "    Returns:\n",
    "    Cross Entropy Cost\n",
    "    \"\"\"\n",
    "    # sanity checks:\n",
    "    try:\n",
    "        if ypred.shape != y.shape:\n",
    "            raise AttributeError(\"The two input arguments ypred and y should be numpy arrays of the same shape.\")\n",
    "    except Exception:\n",
    "        raise AttributeError(\"Wrong type of argument - ypred and y should be a numpy array\")\n",
    "\n",
    "    # clip predicted values and compute the cost\n",
    "    \n",
    "    ### START YOUR CODE ### \n",
    "    ypred = np.clip(ypred, eps, 1-eps)\n",
    "    J = - 1/y.shape[1] * np.sum(y * np.log(ypred) + (1-y) * np.log(1-ypred))\n",
    "    ### END YOUR CODE ### \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# CASE 1: Numeric value computed correctly\n",
    "yhat = np.array([0.1,0.2,0.5,0.8,0.9,1.0]).reshape(1,6)\n",
    "yunittest = np.array([0,1,1,0,1,1]).reshape(1,6)\n",
    "J = cost_CE(yhat,yunittest)\n",
    "Jtrue = -(np.log(0.2)+np.log(0.5)+np.log(0.9)+np.log(1.0)+np.log(0.9)+np.log(0.2))/6\n",
    "np.testing.assert_array_almost_equal(J,Jtrue,decimal=8)\n",
    "\n",
    "# CASE 2: Both arguments should be numpy arrays of the same shape\n",
    "try:\n",
    "    cost_CE(1,1)\n",
    "except AttributeError:\n",
    "    print(\"Exception ok\")\n",
    "    \n",
    "# CASE 3: Both arguments should be numpy arrays of the same shape\n",
    "try:\n",
    "    cost_CE(yhat,1)\n",
    "except AttributeError:\n",
    "    print(\"Exception ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cost_MSE(ypred, y):\n",
    "    \"\"\"\n",
    "    Computes the mean square error cost function for given predicted values and labels.\n",
    "    \n",
    "    Parameters:\n",
    "    ypred -- A scalar or numpy array with shape (1,m).\n",
    "    y -- A scalar or numpy array with shape (1,m).\n",
    "    \n",
    "    Returns:\n",
    "    MSE Cost\n",
    "    \"\"\"    \n",
    "    # sanity checks:\n",
    "    try:\n",
    "        if ypred.shape != y.shape:\n",
    "            raise AttributeError(\"The two input arguments ypred and y should be numpy arrays of the same shape.\")\n",
    "    except Exception:\n",
    "        raise AttributeError(\"Wrong type of argument - ypred and y should be a numpy array\")\n",
    "\n",
    "    ### START YOUR CODE ### \n",
    "    J = 1/(2*y.shape[1]) * np.sum((ypred - y)**2)\n",
    "\n",
    "    ### END YOUR CODE ### \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# CASE 1: Numeric value computed correctly\n",
    "yhat = np.array([0.1,0.2,0.5,0.8,0.9,1.0]).reshape(1,6)\n",
    "yunittest = np.array([0,1,1,0,1,1]).reshape(1,6)\n",
    "J = cost_MSE(yhat,yunittest)\n",
    "Jtrue = (0.01+0.64+0.25+0.64+0.01)/12\n",
    "np.testing.assert_almost_equal(J,Jtrue,decimal=8)\n",
    "\n",
    "# CASE 2: Both arguments should be numpy arrays of the same shape\n",
    "try:\n",
    "    cost_MSE(1,1)\n",
    "except AttributeError:\n",
    "    print(\"Exception ok\")\n",
    "    \n",
    "# CASE 3: Both arguments should be numpy arrays of the same shape\n",
    "try:\n",
    "    cost_MSE(yhat,1)\n",
    "except AttributeError:\n",
    "    print(\"Exception ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Rules for the Parameters\n",
    "\n",
    "Different update rules associated with the different cost functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def step_CE(X, Y, Ypred):\n",
    "    \"\"\"\n",
    "    Computes the update of the weights and bias from the gradient of the cross entropy cost. \n",
    "    \n",
    "    Arguments:\n",
    "    X -- data of size (n, m)\n",
    "    Y -- label vector (1, m)\n",
    "    Ypred -- predicted scores (1, m)\n",
    "\n",
    "    Returns: \n",
    "    Dictionary with the gradient w.r.t. weights ('dw') and w.r.t. bias ('db')\n",
    "    \"\"\"\n",
    "\n",
    "    ### START YOUR CODE ### \n",
    "    dw = ((Ypred - Y) * X).mean(axis=1)\n",
    "    dw = np.expand_dims(dw, axis=0)\n",
    "    \n",
    "    db = (Ypred - Y).mean(axis=1)\n",
    "    db = np.expand_dims(db, axis=0)\n",
    "    ### END YOUR CODE ### \n",
    "    \n",
    "    return {\"dw\": dw, \"db\": db}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "xunittest = np.array([[1,2,3],[4,5,6]]).reshape(2,3)\n",
    "yunittest = np.array([1,0,1]).reshape(1,3)\n",
    "ypred = np.array([0.8,0.3,0.9]).reshape(1,3)\n",
    "\n",
    "res = step_CE(xunittest,yunittest,ypred)\n",
    "dwtrue = np.array([0.033333333,0.033333333]).reshape(1,2)\n",
    "np.testing.assert_almost_equal(res[\"dw\"],dwtrue,decimal=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def step_MSE(X, Y, Ypred):\n",
    "    \"\"\"\n",
    "    Computes the update of the weights and bias from the gradient of the mean square error cost. \n",
    "\n",
    "    Arguments:\n",
    "    X -- data of size (n, m)\n",
    "    Y -- label vector (1, m)\n",
    "    Ypred -- predicted scores (1, m)\n",
    "\n",
    "    Returns:\n",
    "    Dictionary with the gradient w.r.t. weights ('dw') and w.r.t. bias ('db')\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START YOUR CODE ### \n",
    "    dw = (Ypred * (1-Ypred) * (Ypred - Y) * X).mean(axis=1)\n",
    "    dw = np.expand_dims(dw, axis=0)\n",
    "    \n",
    "    db = (Ypred * (1-Ypred) * (Ypred - Y)).mean(axis=1)\n",
    "    db = np.expand_dims(db, axis=0)\n",
    "    ### END YOUR CODE ### \n",
    "        \n",
    "    return {\"dw\": dw, \"db\": db}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "xunittest = np.array([[1,2,3],[4,5,6]]).reshape(2,3)\n",
    "yunittest = np.array([1,0,1]).reshape(1,3)\n",
    "ypred = np.array([0.8,0.3,0.9]).reshape(1,3)\n",
    "\n",
    "res = step_MSE(xunittest,yunittest,ypred)\n",
    "dwtrue = np.array([0.02233333,0.04433333]).reshape(1,2)\n",
    "np.testing.assert_almost_equal(res[\"dw\"],dwtrue,decimal=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def error_rate(Ypred, Y):\n",
    "    \"\"\"\n",
    "    Computes the error rate defined as the fraction of misclassified samples.\n",
    "    \n",
    "    Arguments:\n",
    "    Ypred -- predicted scores with values in [0,1], array of shape (1,m)\n",
    "    Y -- ground truth labels with values in {0,1}, array of shape (1,m)\n",
    "\n",
    "    Returns:\n",
    "    error_rate \n",
    "    \"\"\"\n",
    "    ### START YOUR CODE ### \n",
    "    return (np.round(Ypred) != Y).mean()\n",
    "    ### END YOUR CODE ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "yunittest = np.array([1,0,1,1,0])\n",
    "ypred = np.array([0.9,0.1,0.4,0.8,0.7])\n",
    "np.testing.assert_almost_equal(error_rate(ypred, yunittest),0.4,decimal=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Parameters\n",
    "\n",
    "First we provide a utility method to generate properly intialized parameters. You will learn later more details about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_params(n, random=False):\n",
    "    \"\"\"\n",
    "    This function provides initialized parameters: a vector of shape (1,n) as weights and a scalar equal to zero as bias. \n",
    "    \n",
    "    Argument:\n",
    "    n -- size of the w vector we want (number of features)\n",
    "    rand -- if set to True stand norma distributed values are set for the weights; otherwise zeros are used.\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (1,n)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    if random:\n",
    "        w = np.random.randn(*(1,n)) / np.sqrt(n)\n",
    "    else:\n",
    "        w = np.zeros((1,n))\n",
    "    b = 0.0\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "w0, b0 = initialize_params(100)\n",
    "np.testing.assert_array_equal(w0.shape, (1,100))\n",
    "\n",
    "w0, b0 = initialize_params(100, random=True)\n",
    "np.testing.assert_array_equal(w0.shape, (1,100))\n",
    "np.testing.assert_almost_equal(np.mean(w0),0.0,decimal=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics Class\n",
    "\n",
    "For not littering the optimization loop with code to keep track of the learning results over the epochs we defined a suitable metrics class that keeps all the data (cost function, classification error vs epochs). It also provides utility methods for updating, printing values or plotting the learning curves.\n",
    "\n",
    "It is defined as python class the metrics object then needs to be instantiated from. It means that some small knowledge about object-oriented programming is needed here.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    \"\"\"\n",
    "    Allows to collect statistics (such as classification error or cost) that are of interest over the course of training\n",
    "    and for creating learning curves that are a useful tool for analyzing the quality of the learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cost_function=cost_CE):\n",
    "        \"\"\"\n",
    "        Constructor for a metrics object. \n",
    "        Initializes all the statistics to track in form of python lists.\n",
    "        \n",
    "        Parameters:\n",
    "        cost_function -- a function object that allows to compute the cost.\n",
    "        \"\"\"\n",
    "        self.epochs = []\n",
    "        self.train_costs = []\n",
    "        self.test_costs = []\n",
    "        self.train_errors = []\n",
    "        self.test_errors = []\n",
    "        self.stepsize_w = []\n",
    "        self.stepsize_b = []\n",
    "        self.cost_function = cost_function\n",
    "    \n",
    "    def update(self, epoch, ypred_train, y_train, ypred_test, y_test, dw, db):\n",
    "        \"\"\"\n",
    "        Allows to update the statistics to be tracked for a new epoch.\n",
    "        The cost is computed by using the function object passed to the constructor.\n",
    "        \n",
    "        Parameters:\n",
    "        epoch -- Epoch\n",
    "        ypred_train -- predicted values on the training samples, a numpy array of shape (1,m1)\n",
    "        y_train -- ground truth labels associated with the training samples, a numpy array of shape (1,m1)\n",
    "        ypred_test -- predicted values on the test samples, a numpy array of shape (1,m2)\n",
    "        y_test -- ground truth labels associated with the test samples, a numpy array of shape (1,m2)\n",
    "        dw -- some lenght measure for the gradient w.r.t. the weights, a scalar\n",
    "        db -- gradient w.r.t. the bias, a scalar\n",
    "        \"\"\"       \n",
    "        Jtrain = self.cost_function(ypred_train, y_train)\n",
    "        Jtest = self.cost_function(ypred_test, y_test)\n",
    "        train_error = error_rate(ypred_train, y_train)\n",
    "        test_error = error_rate(ypred_test, y_test)\n",
    "\n",
    "        self.epochs.append(epoch)\n",
    "        self.train_costs.append(Jtrain)\n",
    "        self.test_costs.append(Jtest)\n",
    "        self.train_errors.append(train_error)\n",
    "        self.test_errors.append(test_error)\n",
    "        self.stepsize_w.append(dw)\n",
    "        self.stepsize_b.append(db)\n",
    "        \n",
    "    def print_latest_errors(self):\n",
    "        print (\"Train/test error after epoch %i: %f, %f (min: %f, %f)\" %(self.epochs[-1], self.train_errors[-1], self.test_errors[-1], min(self.train_errors), min(self.test_errors)))\n",
    "    \n",
    "    def print_latest_costs(self):\n",
    "        print (\"Train/test cost after epoch %i: %f, %f\" %(self.epochs[-1], self.train_costs[-1], self.test_costs[-1]))\n",
    "\n",
    "    def plot_cost_curves(self, ymin=None, ymax=None, logy=True):\n",
    "        minvalue = 1e-5\n",
    "        if logy:\n",
    "            plt.semilogy(self.epochs, self.train_costs, \"b-\", label=\"train\")\n",
    "            plt.semilogy(self.epochs, self.test_costs, \"r-\", label=\"test\")\n",
    "        else:\n",
    "            plt.plot(self.epochs, self.train_costs, \"b-\", label=\"train\")\n",
    "            plt.plot(self.epochs, self.test_costs, \"r-\", label=\"test\")            \n",
    "            minvalue = 0.0\n",
    "        plt.ylabel('Cost')\n",
    "        plt.xlabel('Epochs')\n",
    "        xmax = self.epochs[-1]\n",
    "        if not ymin:\n",
    "            ymin = min(max(minvalue,np.min(self.train_costs)),max(minvalue,np.min(self.test_costs))) * 0.8\n",
    "        if not ymax:\n",
    "            ymax = max(np.max(self.train_costs),np.max(self.test_costs)) * 1.2\n",
    "        plt.axis([0,xmax,ymin,ymax])\n",
    "        plt.legend()\n",
    "        plt.show()        \n",
    "    \n",
    "    def plot_error_curves(self, ymin=None, ymax=None, logy=True):\n",
    "        minvalue = 1e-5\n",
    "        if logy:\n",
    "            plt.semilogy(self.epochs, self.train_errors, \"b-\", label=\"train\")\n",
    "            plt.semilogy(self.epochs, self.test_errors, \"r-\", label=\"test\")\n",
    "        else:\n",
    "            plt.plot(self.epochs, self.train_errors, \"b-\", label=\"train\")\n",
    "            plt.plot(self.epochs, self.test_errors, \"r-\", label=\"test\")            \n",
    "            minvalue = 0.0\n",
    "        plt.ylabel('Errors')\n",
    "        plt.xlabel('Epochs')\n",
    "        xmax = self.epochs[-1]\n",
    "        if not ymin:\n",
    "            ymin = min(max(minvalue,np.min(self.train_errors)),max(minvalue,np.min(self.test_errors))) * 0.8\n",
    "        if not ymax:\n",
    "            ymax = max(np.max(self.train_errors),np.max(self.test_errors)) * 1.2\n",
    "        plt.axis([0,xmax,ymin,ymax])\n",
    "        plt.legend()\n",
    "        plt.show()        \n",
    "\n",
    "    def plot_stepsize_curves(self, ymin=None, ymax=None):\n",
    "        plt.semilogy(self.epochs, self.stepsize_w, label=\"dw\")\n",
    "        plt.semilogy(self.epochs, self.stepsize_b, label=\"db\")\n",
    "        plt.ylabel('Step Sizes (dw,db)')\n",
    "        plt.xlabel('Epochs')\n",
    "        xmax = self.epochs[-1]\n",
    "        if not ymin:\n",
    "            ymin = min(max(1e-5,np.min(self.stepsize_w)),max(1e-5,np.min(self.stepsize_b))) * 0.8\n",
    "        if not ymax:\n",
    "            ymax = max(np.max(self.stepsize_w),np.max(self.stepsize_b)) * 1.2\n",
    "        plt.axis([0,xmax,ymin,ymax])\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def optimize(w, b, x_train, y_train, x_test, y_test, nepochs, alpha, cost_type=\"CE\", debug = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running (batch) gradient descent.\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (1,n)\n",
    "    b -- bias, a scalar\n",
    "    x -- array of samples of shape (n,m)\n",
    "    y -- ground truth labels vector (containing 0 or 1) of shape (1, m)\n",
    "    nepochs -- number of iterations of the optimization loop\n",
    "    alpha -- learning rate of the gradient descent update rule\n",
    "    cost -- type of cost function to use for the opimisation (CE or MSE)\n",
    "    debug -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    metrics -- Metrics object that contains metrics collected while training was in progress    \n",
    "    \"\"\" \n",
    "    if \"CE\" == cost_type:\n",
    "        cost_function = cost_CE\n",
    "        step_function = step_CE\n",
    "    else:\n",
    "        cost_function = cost_MSE\n",
    "        step_function = step_MSE\n",
    "    \n",
    "    metrics = Metrics(cost_function=cost_function)\n",
    "\n",
    "    # compute and set the initial values for the metrics curves  \n",
    "    ypred_train = predict(w,b,x_train)\n",
    "    ypred_test = predict(w,b,x_test)    \n",
    "    metrics.update(0, ypred_train, y_train, ypred_test, y_test, 0, 0)\n",
    "    \n",
    "    ### START YOUR CODE ###\n",
    "    for e in range(nepochs):\n",
    "        ypred_train = predict(w,b,x_train)\n",
    "        ypred_test = predict(w,b,x_test)    \n",
    "        \n",
    "        step = step_function(x_train, y_train, ypred_train)\n",
    "        w -= alpha * step['dw']\n",
    "        b -= alpha * step['db']\n",
    "        \n",
    "        metrics.update(e, ypred_train, y_train, ypred_test, y_test, \n",
    "                       np.linalg.norm(step['dw']), np.linalg.norm(step['db']))\n",
    "        \n",
    "        if debug:\n",
    "            metrics.print_latest_costs()\n",
    "            metrics.print_latest_errors()\n",
    "    ### END YOUR CODE ### \n",
    "        \n",
    "    # finally, we print the latest metrics values and return\n",
    "    #metrics.print_latest_costs()\n",
    "    metrics.print_latest_errors()\n",
    "\n",
    "    return {\"w\": w, \"b\": b}, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the Training for Specific Settings\n",
    "\n",
    "#### A first run\n",
    "Compose that all in a single \"pipeline\" starting with selecting the digits in the data preparation up to performing the training.\n",
    "\n",
    "Make a first test run with \n",
    "* learning rate 0.2\n",
    "* 500 epochs\n",
    "* CE loss\n",
    "\n",
    "The training should not take more than a couple of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data\n",
    "selected_digits = (1,7)\n",
    "\n",
    "### START YOUR CODE ###\n",
    "x1, y1 = filter_digits(x, y, selected_digits=selected_digits)\n",
    "x_train1, x_test1, y_train, y_test = prepare_train_test(x1, y1, test_size=0.2)\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training here\n",
    "\n",
    "### START YOUR CODE ###\n",
    "np.random.seed(1) # this makes the results reproduceable - change this if you want to see other initial weights\n",
    "\n",
    "learning_rate = 0.2\n",
    "nepochs = 500\n",
    "\n",
    "w, b = initialize_params(x_train.shape[0])\n",
    "params, metrics = optimize(w, b, x_train1, y_train, x_test1, y_test, nepochs, \n",
    "                           learning_rate, cost_type=\"CE\", debug = True)\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Learning Curves\n",
    "\n",
    "Cost <br>\n",
    "Error Rate <br>\n",
    "Learning Speed (Lenght of Parameter Change)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_cost_curves(ymin=0.001, ymax=0.2,logy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_error_curves(ymin=0.001, ymax=0.02,logy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_stepsize_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot misclassified digits \n",
    "\n",
    "Plot misclassified digits and judge (with your human eye) whether the given digits should have been correctly recognized by the model or whether the digit is written with a bad handwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ### \n",
    "learned_w = params['w']\n",
    "learned_b = params['b']\n",
    "ypred_test = predict(learned_w, learned_b, x_test)  \n",
    "print('test error rate: %0.4f %%' % (error_rate(ypred_test, y_test) * 100))\n",
    "\n",
    "wrong_predicted = (np.round(ypred_test) != y_test).squeeze()\n",
    "wrong_predicted = np.argwhere(wrong_predicted > 0)[:, 0]\n",
    "\n",
    "plot_digits(x_test, y_test, wrong_predicted,\n",
    "            shape, selected_digits, cols=5)\n",
    "### END YOUR CODE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Dependency on Learning Rate and #Epochs \n",
    "\n",
    "Try different learning rates (e.g. 0.1, 0.2, 0.5, 1.0) and explore how many epochs you need to obtain stable results.\n",
    "* Inspect the error rate curves to make sure that the rates reported in the table are stable. \n",
    "* Describe the characteristic behavior of the error rate curves for different learning rates. \n",
    "* Summarize the results in a small table with (learning rate, # epochs, training and test error rates.\n",
    "* Estimate the error bar in the estimation of the test error rates when varying the iniitial weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrins solution is cool here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Dependency on Cost Function\n",
    "\n",
    "Compare the train and test error curves for the learning rate 0.2 when using cross-entropy loss with when using the mean square error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes the results reproduceable - change this if you want to see other initial weights\n",
    "np.random.seed(1) \n",
    "\n",
    "# preparing data\n",
    "selected_digits = (1,7)\n",
    "x1, y1 = filter_digits(x, y, selected_digits=selected_digits)\n",
    "x_train1, x_test1, y_train, y_test = prepare_train_test(x1, y1, test_size=0.2)\n",
    "\n",
    "# params\n",
    "learning_rate = 0.2\n",
    "nepochs = 500\n",
    "\n",
    "# CE\n",
    "w, b = initialize_params(x_train.shape[0])\n",
    "params, metrics = optimize(w, b, x_train1, y_train, x_test1, y_test, nepochs, \n",
    "                           learning_rate, cost_type=\"CE\", debug=False)\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('Error CE')\n",
    "metrics.plot_error_curves(ymin=0.001, ymax=0.02,logy=False)\n",
    "\n",
    "# MSE\n",
    "w, b = initialize_params(x_train.shape[0])\n",
    "params, metrics = optimize(w, b, x_train1, y_train, x_test1, y_test, nepochs, \n",
    "                           learning_rate, cost_type=\"MSE\", debug=False)\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('Error MSE')\n",
    "metrics.plot_error_curves(ymin=0.001, ymax=0.02,logy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Determine the error rates for different digit pairs\n",
    "\n",
    "For which digit pairs do you obtain good classification results (measured with the test error rates) - for which not so good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here as well, take Andrins solution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
