{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation, Parameter Initialisation, Batchnorm, Optimisers\n",
    "\n",
    "Create and compare different models (as described below).\n",
    "\n",
    "Inspect the results by using tensorboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28**2)\n",
    "x_test = x_test.reshape(-1, 28**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layersizes = [50,50,50,10]\n",
    "batchsize = 32 \n",
    "epochs = 20\n",
    "learning_rate = 0.1\n",
    "\n",
    "tensorboard_folder = \"tb_logs_keras\"\n",
    "outdir = os.path.join(os.getcwd(), tensorboard_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "* No regularisation\n",
    "* No Batch Norm\n",
    "* Default parameter initialisation of Keras: What is the default?\n",
    "* Sigmoid activation (last layer always softmax)\n",
    "* SGD with given batchsize and learning rate, no accelerators (no momentum nor RMS prop).\n",
    "\n",
    "Now, create the baseline model. \n",
    "\n",
    "Possibly, add convenient naming to the layers so that you can more easily read the outputs in tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(layersizes, activation):\n",
    "    \"\"\"\n",
    "    Provides an MLP model (using Sequential) with given layersizes. The last layer is a softmax layer.\n",
    "    As activation function use sigmoid.\n",
    "        \n",
    "    Arguments:\n",
    "    layersizes -- list of integers with the number of hidden units per layer. The last element is for MNIST 10.\n",
    "    activation -- string specifying the activation function for the hidden layers to be used.\n",
    "    \n",
    "    \"\"\"\n",
    "    ### START YOUR CODE HERE ###\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=28**2))\n",
    "    for i, layer_size in enumerate(layersizes[:-1]):\n",
    "        model.add(tf.keras.layers.Dense(layer_size, activation=activation, name='hidden_layer_{}'.format(i)))\n",
    "    model.add(tf.keras.layers.Dense(layersizes[-1], activation='softmax', name='output_layer'))\n",
    "    ### STOP YOUR CODE HERE ###\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model\n",
    "\n",
    "Use cross entropy as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_0 (Dense)       (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 44,860\n",
      "Trainable params: 44,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 1.9319 - accuracy: 0.3193 - val_loss: 1.0315 - val_accuracy: 0.6466\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7411 - accuracy: 0.7724 - val_loss: 0.5075 - val_accuracy: 0.8652\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4386 - accuracy: 0.8791 - val_loss: 0.3605 - val_accuracy: 0.8992\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3214 - accuracy: 0.9104 - val_loss: 0.2714 - val_accuracy: 0.9248\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2587 - accuracy: 0.9277 - val_loss: 0.2294 - val_accuracy: 0.9358\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2161 - accuracy: 0.9389 - val_loss: 0.2037 - val_accuracy: 0.9433\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1866 - accuracy: 0.9464 - val_loss: 0.1965 - val_accuracy: 0.9433\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1660 - accuracy: 0.9524 - val_loss: 0.1669 - val_accuracy: 0.9511\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1490 - accuracy: 0.9569 - val_loss: 0.1647 - val_accuracy: 0.9513\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1368 - accuracy: 0.9606 - val_loss: 0.1523 - val_accuracy: 0.9556\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1255 - accuracy: 0.9643 - val_loss: 0.1533 - val_accuracy: 0.9553\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1166 - accuracy: 0.9665 - val_loss: 0.1452 - val_accuracy: 0.9588\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1080 - accuracy: 0.9692 - val_loss: 0.1379 - val_accuracy: 0.9597\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1010 - accuracy: 0.9715 - val_loss: 0.1344 - val_accuracy: 0.9612\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0949 - accuracy: 0.9722 - val_loss: 0.1362 - val_accuracy: 0.9592\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0899 - accuracy: 0.9737 - val_loss: 0.1331 - val_accuracy: 0.9619\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.1367 - val_accuracy: 0.9592\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.1308 - val_accuracy: 0.9619\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0755 - accuracy: 0.9785 - val_loss: 0.1260 - val_accuracy: 0.9640\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0711 - accuracy: 0.9793 - val_loss: 0.1327 - val_accuracy: 0.9616\n"
     ]
    }
   ],
   "source": [
    "run_name = \"baseline\"\n",
    "rundir = os.path.join(outdir, run_name)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=rundir, histogram_freq=1, profile_batch=0)\n",
    "# start tensorboard on command line with tensorboard -logs <path to outdir> \n",
    "\n",
    "\n",
    "### START YOUR CODE HERE ###\n",
    "model = baseline_model(layersizes, 'sigmoid')\n",
    "model.summary()\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=batchsize, \n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tensorboard_callback])\n",
    "### STOP YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUTs\n",
    "\n",
    "Provide here suitable plots and comments:\n",
    "\n",
    "* Learning curves: train / test accuracy and loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Initialisation\n",
    "\n",
    "* No regularisation\n",
    "* No Batch Norm\n",
    "* __Parameter Initialisation: Compare GlorotNormal, Random Normal (mean 0, stdev 1), Zero, HeNormal__\n",
    "* __Sigmoid Activation (last layer always softmax): Compare Sigmoid, ReLu__\n",
    "* SGD with given batchsize and learning rate, no accelerators (no momentum nor RMS prop).\n",
    "\n",
    "Hence, for each of the 4 initializers train and test a model sigmoid and relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_param_init(layersizes, initializer, activation):\n",
    "    \"\"\"\n",
    "    Provides an MLP model (using Sequential) with given layersizes. The last layer is a softmax layer.\n",
    "    As activation function use sigmoid.\n",
    "        \n",
    "    Arguments:\n",
    "    layersizes -- list of integers with the number of hidden units per layer. The last element is for MNIST 10.\n",
    "    initializer -- weight initializer\n",
    "    activation -- string specifying the activation function to be used.\n",
    "    \n",
    "    \"\"\"\n",
    "    ### START YOUR CODE HERE ###\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=28**2))\n",
    "    for i, layer_size in enumerate(layersizes[:-1]):\n",
    "        model.add(tf.keras.layers.Dense(layer_size, \n",
    "                                        activation=activation,\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        bias_initializer=initializer,\n",
    "                                        name='hidden_layer_{}'.format(i)))\n",
    "    model.add(tf.keras.layers.Dense(layersizes[-1], activation='softmax', name='output_layer'))\n",
    "    ### STOP YOUR CODE HERE ###\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model\n",
    "\n",
    "Run with the different settings.\n",
    "Don't forget to configure the proper tensorboard callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Act: SIGMOID, Init: GLOROT_NORMAL\n",
      "--------------------------------------------------\n",
      "final loss: 0.0657 (train), 0.1157 (val)\n",
      "final acc: 0.9811 (train), 0.9656 (val)\n",
      "--------------------------------------------------\n",
      "Act: SIGMOID, Init: RANDOM_NORMAL\n",
      "--------------------------------------------------\n",
      "final loss: 0.0870 (train), 0.1374 (val)\n",
      "final acc: 0.9753 (train), 0.9613 (val)\n",
      "--------------------------------------------------\n",
      "Act: SIGMOID, Init: ZEROS\n",
      "--------------------------------------------------\n",
      "final loss: 1.4306 (train), 1.4114 (val)\n",
      "final acc: 0.3955 (train), 0.4015 (val)\n",
      "--------------------------------------------------\n",
      "Act: SIGMOID, Init: HE_NORMAL\n",
      "--------------------------------------------------\n",
      "final loss: 0.0625 (train), 0.1181 (val)\n",
      "final acc: 0.9822 (train), 0.9671 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: GLOROT_NORMAL\n",
      "--------------------------------------------------\n",
      "final loss: 0.0163 (train), 0.1417 (val)\n",
      "final acc: 0.9948 (train), 0.9697 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: RANDOM_NORMAL\n",
      "--------------------------------------------------\n",
      "final loss: 0.0191 (train), 0.1230 (val)\n",
      "final acc: 0.9935 (train), 0.9737 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: ZEROS\n",
      "--------------------------------------------------\n",
      "final loss: 2.3018 (train), 2.3039 (val)\n",
      "final acc: 0.1127 (train), 0.1060 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: HE_NORMAL\n",
      "--------------------------------------------------\n",
      "final loss: 0.0193 (train), 0.1513 (val)\n",
      "final acc: 0.9937 (train), 0.9666 (val)\n"
     ]
    }
   ],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "import itertools\n",
    "\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "activations = ['sigmoid', 'relu']\n",
    "initializations = ['glorot_normal', 'random_normal', 'zeros', 'he_normal']\n",
    "\n",
    "for act, init in itertools.product(activations, initializations):\n",
    "    print('-'*50)\n",
    "    print('Act: {0}, Init: {1}'.format(act.upper(), init.upper()))\n",
    "    print('-'*50)\n",
    "    \n",
    "    run_name = 'param-init-{0}-{1}'.format(act, init)\n",
    "    rundir = os.path.join(outdir, run_name)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=rundir, histogram_freq=1, profile_batch=0)\n",
    "    \n",
    "    model = model_param_init(layersizes, init, act)\n",
    "    model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        batch_size=batchsize, \n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[tensorboard_callback],\n",
    "                        verbose=False)\n",
    "    \n",
    "    print('final loss: {0:.4f} (train), {1:.4f} (val)'.format(history.history['loss'][-1], \n",
    "                                                              history.history['val_loss'][-1]))\n",
    "    print('final acc: {0:.4f} (train), {1:.4f} (val)'.format(history.history['accuracy'][-1], \n",
    "                                                             history.history['val_accuracy'][-1]))\n",
    "### STOP YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUTs\n",
    "\n",
    "Provide here suitable plots and comments:\n",
    "\n",
    "* Comparison of the different learning curves: \n",
    "    * train accuracy vs epochs for different models\n",
    "    * train loss vs epochs for different models\n",
    "    * test accuracy vs epochs for different models\n",
    "    * test loss vs epochs for different models\n",
    "    \n",
    "Interpret the result and report your findings: Is it consistent with what you have learned in the lecture?\n",
    "\n",
    "Are there ways (e.g. change in model) so that the effects of parameter initialisation become more clear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalisation\n",
    "\n",
    "* No regularisation\n",
    "* __Batch Norm__: with / without \n",
    "* __Parameter Initialisation: Random Normal (0,1), GlorotNormal__\n",
    "* __Activation: Compare Sigmoid, ReLu__\n",
    "* SGD with given batchsize and learning rate, no accelerators (no momentum nor RMS prop).\n",
    "\n",
    "Run with/without batchnorm in combination with sigmoid or relu (with GlorotNormal).<br>\n",
    "Run with/without batchnorm in combination with GlorotNormal or RandomNormal (with sigmoid).<br>\n",
    "Hence run 8 different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_batchnorm(layersizes, initializer, activation):\n",
    "    \"\"\"\n",
    "    Provides an MLP model (using Sequential) with given layersizes. The last layer is a softmax layer.\n",
    "    As activation function use sigmoid.\n",
    "        \n",
    "    Arguments:\n",
    "    layersizes -- list of integers with the number of hidden units per layer. The last element is for MNIST 10.\n",
    "    initializer -- weight initializer\n",
    "    activation -- string specifying the activation function to be used.\n",
    "    \"\"\"\n",
    "    ### START YOUR CODE HERE ###\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=28**2))\n",
    "    for i, layer_size in enumerate(layersizes[:-1]):\n",
    "        model.add(tf.keras.layers.Dense(layer_size, \n",
    "                                        activation=None,\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        bias_initializer=initializer,\n",
    "                                        name='hidden_layer_{}'.format(i)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Activation(activation))\n",
    "    model.add(tf.keras.layers.Dense(layersizes[-1], activation='softmax', name='output_layer'))\n",
    "    ### STOP YOUR CODE HERE ###\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model\n",
    "\n",
    "Run the different variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Act: SIGMOID, Init: GLOROT_NORMAL, Batchnorm: True\n",
      "--------------------------------------------------\n",
      "final loss: 0.0592 (train), 0.0987 (val)\n",
      "final acc: 0.9807 (train), 0.9708 (val)\n",
      "--------------------------------------------------\n",
      "Act: SIGMOID, Init: GLOROT_NORMAL, Batchnorm: False\n",
      "--------------------------------------------------\n",
      "final loss: 0.0660 (train), 0.1211 (val)\n",
      "final acc: 0.9811 (train), 0.9660 (val)\n",
      "--------------------------------------------------\n",
      "Act: SIGMOID, Init: RANDOM_NORMAL, Batchnorm: True\n",
      "--------------------------------------------------\n",
      "final loss: 0.0593 (train), 0.0961 (val)\n",
      "final acc: 0.9816 (train), 0.9720 (val)\n",
      "--------------------------------------------------\n",
      "Act: SIGMOID, Init: RANDOM_NORMAL, Batchnorm: False\n",
      "--------------------------------------------------\n",
      "final loss: 0.0822 (train), 0.1315 (val)\n",
      "final acc: 0.9772 (train), 0.9632 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: GLOROT_NORMAL, Batchnorm: True\n",
      "--------------------------------------------------\n",
      "final loss: 0.0425 (train), 0.0879 (val)\n",
      "final acc: 0.9857 (train), 0.9763 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: GLOROT_NORMAL, Batchnorm: False\n",
      "--------------------------------------------------\n",
      "final loss: 0.0137 (train), 0.1373 (val)\n",
      "final acc: 0.9956 (train), 0.9722 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: RANDOM_NORMAL, Batchnorm: True\n",
      "--------------------------------------------------\n",
      "final loss: 0.0423 (train), 0.0930 (val)\n",
      "final acc: 0.9856 (train), 0.9761 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: RANDOM_NORMAL, Batchnorm: False\n",
      "--------------------------------------------------\n",
      "final loss: 0.0178 (train), 0.1247 (val)\n",
      "final acc: 0.9944 (train), 0.9736 (val)\n"
     ]
    }
   ],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "import itertools\n",
    "\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "activations = ['sigmoid', 'relu']\n",
    "initializations = ['glorot_normal', 'random_normal']\n",
    "batchnorm = [True, False]\n",
    "\n",
    "for act, init, bn in itertools.product(activations, initializations, batchnorm):\n",
    "    print('-'*50)\n",
    "    print('Act: {0}, Init: {1}, Batchnorm: {2}'.format(act.upper(), init.upper(), bn))\n",
    "    print('-'*50)\n",
    "    \n",
    "    run_name = 'batch-norm-{0}-{1}-{2}'.format(act, init, bn)\n",
    "    rundir = os.path.join(outdir, run_name)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=rundir, histogram_freq=1, profile_batch=0)\n",
    "    \n",
    "    if bn:\n",
    "        model = model_batchnorm(layersizes, init, act)\n",
    "    else:\n",
    "        model = model_param_init(layersizes, init, act)\n",
    "        \n",
    "    model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        batch_size=batchsize, \n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[tensorboard_callback],\n",
    "                        verbose=False)\n",
    "    \n",
    "    print('final loss: {0:.4f} (train), {1:.4f} (val)'.format(history.history['loss'][-1], \n",
    "                                                              history.history['val_loss'][-1]))\n",
    "    print('final acc: {0:.4f} (train), {1:.4f} (val)'.format(history.history['accuracy'][-1], \n",
    "                                                             history.history['val_accuracy'][-1]))\n",
    "### STOP YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUTs\n",
    "\n",
    "Provide here suitable plots and comments:\n",
    "\n",
    "* Comparison of the different learning curves: \n",
    "    * train accuracy vs epochs for different models\n",
    "    * train loss vs epochs for different models\n",
    "    * test accuracy vs epochs for different models\n",
    "    * test loss vs epochs for different models\n",
    "    \n",
    "* Inspect the histograms of the activations and compare them for the different models.\n",
    "\n",
    "* Find the max learning rate for the model with and without Batch Norm. \n",
    "\n",
    "Interpret the result and report your findings: Is it consistent with what you have learned in the lecture?\n",
    "\n",
    "Are there ways (e.g. change in model) so that the effects of batch norm become more clear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "\n",
    "* No regularisation\n",
    "* No BatchNorm \n",
    "* Parameter Initialisation: GlorotNormal\n",
    "* Activation: ReLu\n",
    "* Optimizers: Compare \n",
    "    * SGD with given batchsize and learning rate, no accelerators (no momentum nor RMS prop)\n",
    "    * RmsProp\n",
    "    * Momentum\n",
    "\n",
    "Create an according model and train it with the different optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_HAS_AGGREGATE_GRAD',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_aggregate_gradients',\n",
       " '_assert_valid_dtypes',\n",
       " '_call_if_callable',\n",
       " '_checkpoint_dependencies',\n",
       " '_clip_gradients',\n",
       " '_compute_gradients',\n",
       " '_create_all_weights',\n",
       " '_create_hypers',\n",
       " '_create_or_restore_slot_variable',\n",
       " '_create_slots',\n",
       " '_decayed_lr',\n",
       " '_deferred_dependencies',\n",
       " '_deferred_slot_restorations',\n",
       " '_dense_apply_args',\n",
       " '_distributed_apply',\n",
       " '_distribution_strategy',\n",
       " '_distribution_strategy_scope',\n",
       " '_fallback_apply_state',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_hyper',\n",
       " '_handle_deferred_dependencies',\n",
       " '_hyper',\n",
       " '_hypers_created',\n",
       " '_init_set_name',\n",
       " '_initial_decay',\n",
       " '_iterations',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_resources',\n",
       " '_maybe_initialize_trackable',\n",
       " '_momentum',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_prepare',\n",
       " '_prepare_local',\n",
       " '_resource_apply_dense',\n",
       " '_resource_apply_sparse',\n",
       " '_resource_apply_sparse_duplicate_indices',\n",
       " '_resource_scatter_add',\n",
       " '_resource_scatter_update',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_restore_slot_variable',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_hyperparameter',\n",
       " '_set_hyper',\n",
       " '_setattr_tracking',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_slot_names',\n",
       " '_slots',\n",
       " '_sparse_apply_args',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_use_locking',\n",
       " '_valid_dtypes',\n",
       " '_weights',\n",
       " 'add_slot',\n",
       " 'add_weight',\n",
       " 'apply_gradients',\n",
       " 'clipnorm',\n",
       " 'clipvalue',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_gradients',\n",
       " 'get_slot',\n",
       " 'get_slot_names',\n",
       " 'get_updates',\n",
       " 'get_weights',\n",
       " 'iterations',\n",
       " 'minimize',\n",
       " 'nesterov',\n",
       " 'set_weights',\n",
       " 'variables',\n",
       " 'weights']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Act: RELU, Init: GLOROT_NORMAL, Batchnorm: False, Optim: SGD\n",
      "--------------------------------------------------\n",
      "final loss: 0.0230 (train), 0.1599 (val)\n",
      "final acc: 0.9922 (train), 0.9661 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: GLOROT_NORMAL, Batchnorm: False, Optim: RMSprop\n",
      "--------------------------------------------------\n",
      "final loss: 2.3149 (train), 2.3111 (val)\n",
      "final acc: 0.1047 (train), 0.0956 (val)\n",
      "--------------------------------------------------\n",
      "Act: RELU, Init: GLOROT_NORMAL, Batchnorm: False, Optim: SGD_Momentum\n",
      "--------------------------------------------------\n",
      "final loss: 2.3078 (train), 2.3117 (val)\n",
      "final acc: 0.1043 (train), 0.1060 (val)\n"
     ]
    }
   ],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "import itertools\n",
    "\n",
    "\n",
    "activations = ['relu']\n",
    "initializations = ['glorot_normal']\n",
    "batchnorm = [False]\n",
    "\n",
    "momentum = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "momentum._name = 'SGD_Momentum'\n",
    "optimizers = [\n",
    "    tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "    tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "    momentum]\n",
    "\n",
    "for act, init, bn, opt in itertools.product(activations, initializations, batchnorm, optimizers):\n",
    "    print('-'*50)\n",
    "    print('Act: {0}, Init: {1}, Batchnorm: {2}, Optim: {3}'.format(act.upper(), init.upper(), bn, opt._name))\n",
    "    print('-'*50)\n",
    "    \n",
    "    run_name = 'optimizers-{0}-{1}-{2}-{3}'.format(act, init, bn, opt._name)\n",
    "    rundir = os.path.join(outdir, run_name)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=rundir, histogram_freq=1, profile_batch=0)\n",
    "    \n",
    "    if bn:\n",
    "        model = model_batchnorm(layersizes, init, act)\n",
    "    else:\n",
    "        model = model_param_init(layersizes, init, act)\n",
    "        \n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        batch_size=batchsize, \n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[tensorboard_callback],\n",
    "                        verbose=False)\n",
    "    \n",
    "    print('final loss: {0:.4f} (train), {1:.4f} (val)'.format(history.history['loss'][-1], \n",
    "                                                              history.history['val_loss'][-1]))\n",
    "    print('final acc: {0:.4f} (train), {1:.4f} (val)'.format(history.history['accuracy'][-1], \n",
    "                                                             history.history['val_accuracy'][-1]))\n",
    "### STOP YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUTs\n",
    "\n",
    "TODO: \n",
    "* Comparison of the different learning curves: \n",
    "    * train accuracy vs epochs for optimizers\n",
    "    * train loss vs epochs for optimizers\n",
    "    * test accuracy vs epochs for optimizers\n",
    "    * test loss vs epochs for optimizers\n",
    "    \n",
    "Interpret the result and report your findings: Is it consistent with what you have learned in the lecture?\n",
    "\n",
    "Are there ways (e.g. change in model) so that the effects of the different optimizers become more clear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
