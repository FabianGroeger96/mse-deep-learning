{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with sklearn\n",
    "\n",
    "The goal of this exercise is to \n",
    "* explore some of the sklearn functionality for training a MLP classifier (see https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)  \n",
    "* by using cross validation \n",
    "* learn how to compute the confusion matrix and its derived quantities and how to interpret them\n",
    "* explore the test error as a function of the complexity (number of units, number of layers)\n",
    "* explore the impact of L2 regularisation\n",
    "\n",
    "__IMPORTANT REMARK__: We here follow the convention of sklearn to enumerate the samples with the first index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/Users/Apple/Documents/Deep Learning/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x_train,x_test):\n",
    "    \"\"\"\n",
    "    Normalizes the pixels values of the images - mean and stdev are computed from the training set.\n",
    "    \n",
    "    Parameters:\n",
    "    x_train -- Array of training samples of shape (n,m1) where n,m1 are the number of features and samples, respectively.  \n",
    "    x_test -- Array of test samples of shape (n,m2) where n,m2 are the number of features and samples, respectively. \n",
    "    \n",
    "    Returns:\n",
    "    The arrays with the normalized train and test samples.  \n",
    "    \"\"\"\n",
    "    mean = np.mean(x_train)\n",
    "    std = np.std(x_train)\n",
    "    x_train -= mean\n",
    "    x_test -= mean\n",
    "    x_train /= std\n",
    "    x_test /= std\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you have trouble with the fetch_openml, use this code\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = fetch_openml('mnist_784', data_home=datadir, return_X_y=True)\n",
    "x_train0, x_test0, y_train, y_test = train_test_split(x, y, test_size=10000, random_state=1)\n",
    "x_train, x_test = normalize(x_train0, x_test0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Model Family and learn how to compute the metrics\n",
    "\n",
    "#### Model\n",
    "Use the functionality of scikit learn to configure a MLP and its training procedure with\n",
    "* hidden layers: 0-2 layers with suitable number of units per layer\n",
    "* mini-batch gradient descent with given batch_size (no advanced optimisers)\n",
    "* constant learning rate (no learning rate schedules)\n",
    "* number of epochs\n",
    "* no regularisation such as L2 penalty or early stopping\n",
    "\n",
    "#### Metrics\n",
    "Compute the train and test error resp. accuracy as well as the class precision, recall, f1-score.\n",
    "\n",
    "__See__:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "* https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Training Run\n",
    "\n",
    "Run the training and plot the training loss with a first set of values:\n",
    "* no hidden layers\n",
    "* mini-batchsize: 64\n",
    "* learning rate: 0.1\n",
    "* 100 epochs\n",
    "\n",
    "Compute the Metrics.\n",
    "Which digits are hard to predict?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9289833333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x121940730>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Basic Hyperparameters\n",
    "hidden_layer_sizes = ()\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "# Regularisation:\n",
    "alpha = 0.0 # L2 regularisation constant\n",
    "early_stopping = False\n",
    "n_iter_no_change = 10\n",
    "\n",
    "### START YOUR CODE ###\n",
    "# Model instantiation and training\n",
    "\n",
    "model = MLPClassifier(activation='relu', alpha=learning_rate, batch_size=batch_size, early_stopping=False,\n",
    "       hidden_layer_sizes=(),\n",
    "       max_iter=100)\n",
    "\n",
    "model.fit(x_train0, y_train)\n",
    "\n",
    "\n",
    "# Plot loss curve\n",
    "\n",
    "print (model.score(x_train0,y_train))\n",
    "plt.plot(model.loss_curve_)\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9289833333333334\n",
      "Test Acc: 0.9154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       959\n",
      "           1       0.96      0.96      0.96      1186\n",
      "           2       0.94      0.89      0.91      1035\n",
      "           3       0.90      0.89      0.89      1031\n",
      "           4       0.91      0.91      0.91       941\n",
      "           5       0.91      0.85      0.88       930\n",
      "           6       0.93      0.96      0.94       942\n",
      "           7       0.94      0.93      0.93      1050\n",
      "           8       0.83      0.91      0.87       936\n",
      "           9       0.87      0.91      0.89       990\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# train and test error, accuracy\n",
    "# per class accuracy, precision, f1 score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "pred_train = model.predict(x_train0)\n",
    "pred_test = model.predict(x_test0)\n",
    "\n",
    "\n",
    "print(\"Train Acc:\", accuracy_score(y_train, pred_train))\n",
    "print(\"Test Acc:\", accuracy_score(y_test, pred_test))\n",
    "\n",
    "print(classification_report(y_test,pred_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model without Hidden Layer\n",
    "\n",
    "By first varying just the parameters \n",
    "* mini-batchsize\n",
    "* learning rate\n",
    "* epochs\n",
    "\n",
    "with adding any hidden layer.\n",
    "\n",
    "Summarize what the best combination of the abover hyper-parameters is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Apple/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=MLPClassifier(hidden_layer_sizes=()), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.1, 0.2, 0.5], 'batch_size': [32, 64],\n",
       "                         'max_iter': [50, 100]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# Keep hidden_layer_sizes = () \n",
    "# Vary the following\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes = ())\n",
    "\n",
    "parameter_space = {\n",
    "    'alpha': [0.01, 0.1, 0.2, 0.5],\n",
    "    'batch_size' : [32, 64],\n",
    "    'max_iter' : [50, 100] #epochs ?\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(model, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(x_train0, y_train) \n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'batch_size': 64, 'max_iter': 50}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9181666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9361333333333334 0.9164\n"
     ]
    }
   ],
   "source": [
    "train_error = clf.score(x_train0, y_train)\n",
    "test_error = clf.score(x_test0, y_test)\n",
    "\n",
    "print (train_error, test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BEST MODEL__ (no hidden layer)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "nepochs = 50\n",
    "\n",
    "train / validation error : 0.93613 / 0.9164"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding one Hidden layer\n",
    "\n",
    "Explore the performance of the model by varying the parameters \n",
    "* mini-batchsize\n",
    "* learning rate\n",
    "* epochs\n",
    "* complexity (number of units in the one hidden layer)\n",
    "\n",
    "For given complexity, summarize what the best combination of other hyper-parameters is - compute this for several complexities.\n",
    "\n",
    "Compute also the \"best\" train and validation error (or accuracy) for given complexity - as a function of the complexity and plot the curve (for selected number of units - e.g. 10 different values). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# Keep hidden_layer_sizes = () \n",
    "# Vary the following\n",
    "\n",
    "hidden_layer_sizes = [(20,), (50,), (100,)] # just one layer \n",
    "batch_size = [32,64]\n",
    "learning_rate = [0.01, 0.1, 0.2]\n",
    "nepochs = [100, 150, 200]\n",
    "\n",
    "model = MLPClassifier()\n",
    "score = 'accuracy'\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'alpha': learning_rate,\n",
    "    'batch_size' : batch_size,\n",
    "    'max_iter' : nepochs\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(MLPClassifier(solver=\"adam\"), parameter_space, scoring=score, cv=3, n_jobs=-1)\n",
    "clf.fit(x_train0, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "results = clf.cv_results_\n",
    "for i in range(len(results[\"params\"])):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (results[\"mean_test_score\"][i], results[\"std_test_score\"][i] * 2, results[\"params\"][i]))\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test , clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill them after you get the best parameters\n",
    "#batch_size = \n",
    "#alpha =\n",
    "#max_iter =\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,), solver=\"adam\", batch_size=batch_size, learning_rate_init=alpha, max_iter=max_iter)\n",
    "clf.fit(x_train0, y_train)\n",
    "\n",
    "train_error = clf.score(x_train0, y_train)\n",
    "test_error = clf.score(x_test0, y_test)\n",
    "\n",
    "print (train_error, test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error vs Complexity__:\n",
    "\n",
    "Plot with the train and test error vs complexity (number of units in the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(100,), (50,), (10,), (5,)]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf2 = GridSearchCV(model, parameter_space, n_jobs=-1, cv=5)\n",
    "clf2.fit(x_train0, y_train) # X is train samples and y is the corresponding labels\n",
    "\n",
    "\n",
    "\n",
    "#change into the bests\n",
    "#batch_size = \n",
    "#learning_rate = \n",
    "#nepochs = \n",
    "\n",
    "complexity = [10, 20, 50, 100]\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for i in complexity:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (i,), batch_size=batch_size, learning_rate_init=learning_rate, max_iter=nepochs)\n",
    "    mlp.fit(x_train0, y_train)\n",
    "    test_errors.append(mlp.score(x_test0, y_test))\n",
    "    train_errors.append(mlp.score(x_train0, y_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "plt.plot(complexity, train_errors, label=\"train error\")\n",
    "plt.plot(complexity, test_errors, label=\"test error\")\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.legend()\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BEST MODEL__ (one hidden layer)\n",
    "\n",
    "hidden_layer_sizes = (100,)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 0.01 \n",
    "\n",
    "nepochs = 200 \n",
    "\n",
    "train / validation error :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Regularisation\n",
    "\n",
    "Explore the Impact of Using L2 Regularisation (still adding just one hidden layer) again by varying mini-batchsize, learning rate, epochs, complexity.\n",
    "\n",
    "Can you reach a better best model performance (on validation set)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# Vary the following\n",
    "\n",
    "# Basic Hyperparameters\n",
    "hidden_layer_sizes = (100,)\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "# Regularisation:\n",
    "alpha = 0.2 # L2 regularisation constant\n",
    "\n",
    "\n",
    "\n",
    "model3 = MLPClassifier(alpha = alpha)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(100,), (50,), (10,), (5,)],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'batch_size' : [32, 64],\n",
    "    'max_iter' : [50, 100] #epochs ?\n",
    "}\n",
    "\n",
    "\n",
    "score = 'accuracy'\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(solver=\"adam\", alpha=alpha), parameter_space, scoring=score, cv=3, n_jobs=-1)\n",
    "clf.fit(x_train0, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "results = clf.cv_results_\n",
    "for i in range(len(results[\"params\"])):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (results[\"mean_test_score\"][i], results[\"std_test_score\"][i] * 2, results[\"params\"][i]))\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =\n",
    "learning_rate =\n",
    "max_iter = \n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50,), solver=\"adam\", batch_size=batch_size, learning_rate_init=learning_rate, max_iter=100, alpha=0.2)\n",
    "clf.fit(x_train0, y_train)\n",
    "\n",
    "train_error = clf.score(x_train0, y_train)\n",
    "test_error = clf.score(x_test0, y_test)\n",
    "\n",
    "print (train_error, test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error vs Complexity__:\n",
    "\n",
    "Plot with the train and test error vs complexity (number of units in the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "batch_size = \n",
    "learning_rate = \n",
    "nepochs = \n",
    "alpha = 0.2\n",
    "\n",
    "complexity = [10, 20, 50, 100]\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for i in complexity:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (i,), solver=\"adam\", batch_size=batch_size, alpha=alpha, learning_rate_init=learning_rate, max_iter=nepochs)\n",
    "    mlp.fit(x_train0, y_train)\n",
    "    test_errors.append(mlp.score(x_test0, y_test))\n",
    "    train_errors.append(mlp.score(x_train0, y_train))\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(complexity, train_errors, label=\"train error\")\n",
    "plt.plot(complexity, test_errors, label=\"test error\")\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BEST MODEL__ (one hidden layer)\n",
    "\n",
    "hidden_layer_sizes = (*,)\n",
    "\n",
    "batch_size = \n",
    "\n",
    "learning_rate = \n",
    "\n",
    "nepochs = \n",
    "\n",
    "alpha =  # L2 regularisation constant\n",
    "\n",
    "train / validation error :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding up to 3 Hidden Layers\n",
    "\n",
    "Now consider using a model with more than one hidden layer (at max 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# Vary the following\n",
    "\n",
    "# Basic Hyperparameters\n",
    "hidden_layer_sizes = (100,0,0)\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "# Regularisation:\n",
    "alpha = 0.0 # L2 regularisation constant\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error vs Complexity__:\n",
    "\n",
    "Plot with the train and test error vs complexity (number of units in the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "parameter_space = {'hidden_layer' : [(20,), (50,), (100,), \n",
    "                (20,20,), (20,50,), (20,100,), \n",
    "                (20,20,20,), (20,20,50,), (20,20,100,)]\n",
    "               }\n",
    "\n",
    "\n",
    "score = 'accuracy'\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(solver=\"adam\", batch_size=batch_size, learning_rate_init=learning_rate,\n",
    "                                max_iter=nepochs), parameter_space, scoring=score, cv=3, n_jobs=-1)\n",
    "clf.fit(x_train0, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "results = clf.cv_results_\n",
    "for i in range(len(results[\"params\"])):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (results[\"mean_test_score\"][i], results[\"std_test_score\"][i] * 2, results[\"params\"][i]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BEST MODEL__ (1-3 hidden layers)\n",
    "\n",
    "hidden_layer_sizes = (*,*,*)\n",
    "\n",
    "batch_size = \n",
    "\n",
    "learning_rate = \n",
    "\n",
    "nepochs = \n",
    "\n",
    "alpha =  # L2 regularisation constant\n",
    "\n",
    "train / validation error :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of Best Model\n",
    "\n",
    "Test Error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer =\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=hidden_layer, solver=\"adam\", batch_size=batch_size, \n",
    "                    learning_rate_init=learning_rate, max_iter=nepochs, alpha=alpha)\n",
    "clf.fit(x_train0, y_train)\n",
    "\n",
    "train_error = clf.score(x_train0, y_train)\n",
    "test_error = clf.score(x_test0, y_test)\n",
    "\n",
    "print (train_error, test_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
