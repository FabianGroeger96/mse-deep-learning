{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with sklearn\n",
    "\n",
    "The goal of this exercise is to \n",
    "* explore some of the sklearn functionality for training a MLP classifier (see https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)  \n",
    "* by using cross validation \n",
    "* learn how to compute the confusion matrix and its derived quantities and how to interpret them\n",
    "* explore the test error as a function of the complexity (number of units, number of layers)\n",
    "* explore the impact of L2 regularisation\n",
    "\n",
    "__IMPORTANT REMARK__: We here follow the convention of sklearn to enumerate the samples with the first index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/Users/Apple/Documents/Deep Learning/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x_train,x_test):\n",
    "    \"\"\"\n",
    "    Normalizes the pixels values of the images - mean and stdev are computed from the training set.\n",
    "    \n",
    "    Parameters:\n",
    "    x_train -- Array of training samples of shape (n,m1) where n,m1 are the number of features and samples, respectively.  \n",
    "    x_test -- Array of test samples of shape (n,m2) where n,m2 are the number of features and samples, respectively. \n",
    "    \n",
    "    Returns:\n",
    "    The arrays with the normalized train and test samples.  \n",
    "    \"\"\"\n",
    "    mean = np.mean(x_train)\n",
    "    std = np.std(x_train)\n",
    "    x_train -= mean\n",
    "    x_test -= mean\n",
    "    x_train /= std\n",
    "    x_test /= std\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you have trouble with the fetch_openml, use this code\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = fetch_openml('mnist_784', data_home=datadir, return_X_y=True)\n",
    "x_train0, x_test0, y_train, y_test = train_test_split(x, y, test_size=10000, random_state=1)\n",
    "x_train, x_test = normalize(x_train0, x_test0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Model Family and learn how to compute the metrics\n",
    "\n",
    "#### Model\n",
    "Use the functionality of scikit learn to configure a MLP and its training procedure with\n",
    "* hidden layers: 0-2 layers with suitable number of units per layer\n",
    "* mini-batch gradient descent with given batch_size (no advanced optimisers)\n",
    "* constant learning rate (no learning rate schedules)\n",
    "* number of epochs\n",
    "* no regularisation such as L2 penalty or early stopping\n",
    "\n",
    "#### Metrics\n",
    "Compute the train and test error resp. accuracy as well as the class precision, recall, f1-score.\n",
    "\n",
    "__See__:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "* https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Training Run\n",
    "\n",
    "Run the training and plot the training loss with a first set of values:\n",
    "* no hidden layers\n",
    "* mini-batchsize: 64\n",
    "* learning rate: 0.1\n",
    "* 100 epochs\n",
    "\n",
    "Compute the Metrics.\n",
    "Which digits are hard to predict?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1196ff220>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Basic Hyperparameters\n",
    "hidden_layer_sizes = ()\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "# Regularisation:\n",
    "alpha = 0.0 # L2 regularisation constant\n",
    "early_stopping = False\n",
    "n_iter_no_change = 10\n",
    "\n",
    "### START YOUR CODE ###\n",
    "# Model instantiation and training\n",
    "\n",
    "model = MLPClassifier(activation='relu', alpha=learning_rate, batch_size=batch_size, early_stopping=False,\n",
    "       hidden_layer_sizes=(),\n",
    "       max_iter=100)\n",
    "\n",
    "model.fit(x_train0, y_train)\n",
    "\n",
    "\n",
    "# Plot loss curve\n",
    "\n",
    "print (model.score(x_train0,y_train))\n",
    "plt.plot(model.loss_curve_)\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9289\n",
      "Test Acc: 0.9138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       959\n",
      "           1       0.97      0.96      0.96      1186\n",
      "           2       0.90      0.92      0.91      1035\n",
      "           3       0.93      0.85      0.89      1031\n",
      "           4       0.93      0.89      0.91       941\n",
      "           5       0.88      0.86      0.87       930\n",
      "           6       0.94      0.95      0.94       942\n",
      "           7       0.93      0.92      0.93      1050\n",
      "           8       0.83      0.90      0.86       936\n",
      "           9       0.87      0.91      0.89       990\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# train and test error, accuracy\n",
    "# per class accuracy, precision, f1 score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "pred_train = model.predict(x_train0)\n",
    "pred_test = model.predict(x_test0)\n",
    "\n",
    "\n",
    "print(\"Train Acc:\", accuracy_score(y_train, pred_train))\n",
    "print(\"Test Acc:\", accuracy_score(y_test, pred_test))\n",
    "\n",
    "print(classification_report(y_test,pred_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model without Hidden Layer\n",
    "\n",
    "By first varying just the parameters \n",
    "* mini-batchsize\n",
    "* learning rate\n",
    "* epochs\n",
    "\n",
    "with adding any hidden layer.\n",
    "\n",
    "Summarize what the best combination of the abover hyper-parameters is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# Keep hidden_layer_sizes = () \n",
    "# Vary the following\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes = ())\n",
    "\n",
    "parameter_space = {\n",
    "    'alpha': [0.01, 0.1, 0.2, 0.5],\n",
    "    'batch_size' : [32, 64],\n",
    "    'max_iter' : [50, 100] #epochs ?\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(model, parameter_space, n_jobs=-1, cv=5)\n",
    "clf.fit(x_train0, y_train) \n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BEST MODEL__ (no hidden layer)\n",
    "\n",
    "batch_size = \n",
    "\n",
    "learning_rate = \n",
    "\n",
    "nepochs = \n",
    "\n",
    "train / validation error :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding one Hidden layer\n",
    "\n",
    "Explore the performance of the model by varying the parameters \n",
    "* mini-batchsize\n",
    "* learning rate\n",
    "* epochs\n",
    "* complexity (number of units in the one hidden layer)\n",
    "\n",
    "For given complexity, summarize what the best combination of other hyper-parameters is - compute this for several complexities.\n",
    "\n",
    "Compute also the \"best\" train and validation error (or accuracy) for given complexity - as a function of the complexity and plot the curve (for selected number of units - e.g. 10 different values). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-bfdfc61555b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# X is train samples and y is the corresponding labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# Keep hidden_layer_sizes = () \n",
    "# Vary the following\n",
    "\n",
    "hidden_layer_sizes = (100,) # just one layer \n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "\n",
    "\n",
    "model = MLPClassifier()\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(100,), (50,), (10,), (5,)],\n",
    "    'alpha': [0.01, 0.1, 0.5],\n",
    "    'batch_size' : [32, 64],\n",
    "    'max_iter' : [50, 100] #epochs ?\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(model, parameter_space, n_jobs=-1, cv=5)\n",
    "clf.fit(x_train0, y_train) # X is train samples and y is the corresponding labels\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test , clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error vs Complexity__:\n",
    "\n",
    "Plot with the train and test error vs complexity (number of units in the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(100,), (50,), (10,), (5,)]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf2 = GridSearchCV(model, parameter_space, n_jobs=-1, cv=5)\n",
    "clf2.fit(x_train0, y_train) # X is train samples and y is the corresponding labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "test_scores = clf2.cv_results_['mean_test_score']\n",
    "train_scores = clf2.cv_results_['mean_train_score'] \n",
    "\n",
    "plt.plot(test_scores, label='test')\n",
    "plt.plot(train_scores, label='train')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BEST MODEL__ (one hidden layer)\n",
    "\n",
    "hidden_layer_sizes = (*,)\n",
    "\n",
    "batch_size = \n",
    "\n",
    "learning_rate = \n",
    "\n",
    "nepochs = \n",
    "\n",
    "train / validation error :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Regularisation\n",
    "\n",
    "Explore the Impact of Using L2 Regularisation (still adding just one hidden layer) again by varying mini-batchsize, learning rate, epochs, complexity.\n",
    "\n",
    "Can you reach a better best model performance (on validation set)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# Vary the following\n",
    "\n",
    "# Basic Hyperparameters\n",
    "hidden_layer_sizes = (100,)\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "# Regularisation:\n",
    "alpha = 0.0 # L2 regularisation constant\n",
    "\n",
    "\n",
    "\n",
    "model3 = MLPClassifier(alpha = alpha)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(100,), (50,), (10,), (5,)],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'batch_size' : [32, 64],\n",
    "    'max_iter' : [50, 100] #epochs ?\n",
    "}\n",
    "\n",
    "clf3 = GridSearchCV(model3, parameter_space, n_jobs=-1, cv=5)\n",
    "clf3.fit(x_train0, y_train) # X is train samples and y is the corresponding labels\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error vs Complexity__:\n",
    "\n",
    "Plot with the train and test error vs complexity (number of units in the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "model4 = MLPClassifier()\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(100,), (50,), (10,), (5,)]\n",
    "}\n",
    "\n",
    "clf4 = GridSearchCV(model4, parameter_space, n_jobs=-1, cv=5)\n",
    "clf4.fit(x_train0, y_train) # X is train samples and y is the corresponding labels\n",
    "\n",
    "test_scores = clf4.cv_results_['mean_test_score']\n",
    "train_scores = clf4.cv_results_['mean_train_score'] \n",
    "\n",
    "plt.plot(test_scores, label='test')\n",
    "plt.plot(train_scores, label='train')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BEST MODEL__ (one hidden layer)\n",
    "\n",
    "hidden_layer_sizes = (*,)\n",
    "\n",
    "batch_size = \n",
    "\n",
    "learning_rate = \n",
    "\n",
    "nepochs = \n",
    "\n",
    "alpha =  # L2 regularisation constant\n",
    "\n",
    "train / validation error :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding up to 3 Hidden Layers\n",
    "\n",
    "Now consider using a model with more than one hidden layer (at max 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "# Vary the following\n",
    "\n",
    "# Basic Hyperparameters\n",
    "hidden_layer_sizes = (100,0,0)\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "nepochs = 100\n",
    "\n",
    "# Regularisation:\n",
    "alpha = 0.0 # L2 regularisation constant\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error vs Complexity__:\n",
    "\n",
    "Plot with the train and test error vs complexity (number of units in the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BEST MODEL__ (1-3 hidden layers)\n",
    "\n",
    "hidden_layer_sizes = (*,*,*)\n",
    "\n",
    "batch_size = \n",
    "\n",
    "learning_rate = \n",
    "\n",
    "nepochs = \n",
    "\n",
    "alpha =  # L2 regularisation constant\n",
    "\n",
    "train / validation error :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of Best Model\n",
    "\n",
    "Test Error: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
